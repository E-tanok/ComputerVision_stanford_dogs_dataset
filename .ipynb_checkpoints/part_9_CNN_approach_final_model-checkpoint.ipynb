{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NOTEBOOK_INFORMATION-->\n",
    "<img id=\"r-1060983\" data-claire-element-id=\"1061343\" src=\"http://www.siteduzero.com/favicon.ico\" alt=\"Image utilisateur\">\n",
    "    <p>\n",
    "        **<font color='#D2691E'size=\"6\">Image classification (9/9)</font>**.\n",
    "    </p>\n",
    "    <p>\n",
    "        This notebook allows to train the final neural network, which is used in the <a href=\"http://bit.ly/mk_cv_dogs\">application</a>.\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <center>\n",
    "        **<font color='\t#D2691E'size=\"6\">ROADMAP</font>**\n",
    "    </center>\n",
    "</p>\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"./images/part_9.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "        **<font color='#D2691E'size=\"4\">0) Libraries and functions import</font>**\n",
    "</p>\n",
    "<p>\n",
    "        **<font color='#D2691E'size=\"4\">I) CNN parameters calibration</font>**\n",
    "</p>\n",
    "<p>\n",
    "        **<font color='#D2691E'size=\"4\">II) Model training</font>**\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "        **<font color='#D2691E'size=\"4\">0) Libraries and functions import</font>**\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Flatten,Dense,Dropout\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import SGD, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from context import datasources_path, pickles_path, temp_files_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions_tailored import select_N_random_races\n",
    "from functions_tailored import build_train_validation_and_test_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "        **<font color='#D2691E'size=\"4\">I) CNN parameters calibration</font>**\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>races</th>\n",
       "      <th>training_len</th>\n",
       "      <th>testing_len</th>\n",
       "      <th>n_races</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>fitting_time</th>\n",
       "      <th>prediction_time</th>\n",
       "      <th>epochs_losses</th>\n",
       "      <th>epochs_accuracies</th>\n",
       "      <th>epochs_val_losses</th>\n",
       "      <th>epochs_val_accuracies</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>optimizer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['beagle', 'bernese_mountain_dog', 'dhole', 'e...</td>\n",
       "      <td>982</td>\n",
       "      <td>441</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>7584</td>\n",
       "      <td>109</td>\n",
       "      <td>[11.640229279543377, 8.675667757900571, 6.2707...</td>\n",
       "      <td>[0.13645621251064502, 0.320773934152607, 0.486...</td>\n",
       "      <td>[8.413873997266078, 6.248528911602387, 4.20287...</td>\n",
       "      <td>[0.29411764899643583, 0.43343653213867095, 0.5...</td>\n",
       "      <td>1.335279</td>\n",
       "      <td>0.868481</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['beagle', 'bernese_mountain_dog', 'dhole', 'e...</td>\n",
       "      <td>982</td>\n",
       "      <td>441</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>21151</td>\n",
       "      <td>97</td>\n",
       "      <td>[13.164204929608191, 12.914754133360448, 12.32...</td>\n",
       "      <td>[0.10081466296479076, 0.11099796265727876, 0.1...</td>\n",
       "      <td>[12.512846996909694, 11.754830443084055, 10.95...</td>\n",
       "      <td>[0.10216718466935143, 0.12074303737734862, 0.1...</td>\n",
       "      <td>1.216085</td>\n",
       "      <td>0.854875</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['beagle', 'bernese_mountain_dog', 'dhole', 'e...</td>\n",
       "      <td>982</td>\n",
       "      <td>441</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>5452</td>\n",
       "      <td>97</td>\n",
       "      <td>[11.432109793917467, 6.4637340460192645, 3.881...</td>\n",
       "      <td>[0.16598777837156037, 0.4755600845012548, 0.67...</td>\n",
       "      <td>[8.568536076383324, 4.294536177218883, 3.03362...</td>\n",
       "      <td>[0.3188854513614908, 0.5975232375295538, 0.684...</td>\n",
       "      <td>1.159407</td>\n",
       "      <td>0.884354</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['beagle', 'bernese_mountain_dog', 'dhole', 'e...</td>\n",
       "      <td>982</td>\n",
       "      <td>441</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>11787</td>\n",
       "      <td>98</td>\n",
       "      <td>[12.859470243123786, 11.982571741714011, 10.75...</td>\n",
       "      <td>[0.11608961356572367, 0.13849287499842478, 0.1...</td>\n",
       "      <td>[11.430217060880395, 9.780132278938412, 7.9990...</td>\n",
       "      <td>[0.12074303419412843, 0.18885448999449195, 0.2...</td>\n",
       "      <td>1.033548</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['beagle', 'bernese_mountain_dog', 'dhole', 'e...</td>\n",
       "      <td>982</td>\n",
       "      <td>441</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>3344</td>\n",
       "      <td>97</td>\n",
       "      <td>[10.06785662256773, 4.840170306732116, 3.07574...</td>\n",
       "      <td>[0.2983706677275617, 0.6598778002859376, 0.790...</td>\n",
       "      <td>[5.666034890402212, 3.9021638406688584, 2.7525...</td>\n",
       "      <td>[0.5789473896425206, 0.7151702664584937, 0.798...</td>\n",
       "      <td>2.807766</td>\n",
       "      <td>0.807256</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>['beagle', 'bernese_mountain_dog', 'dhole', 'e...</td>\n",
       "      <td>982</td>\n",
       "      <td>441</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>7370</td>\n",
       "      <td>102</td>\n",
       "      <td>[11.965150679687376, 9.44600970196384, 6.06742...</td>\n",
       "      <td>[0.1395112039661699, 0.29633401464784703, 0.52...</td>\n",
       "      <td>[9.814261461559095, 6.352773416153049, 4.72292...</td>\n",
       "      <td>[0.24767801368568704, 0.49535603161566766, 0.6...</td>\n",
       "      <td>1.040372</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>['beagle', 'bernese_mountain_dog', 'dhole', 'e...</td>\n",
       "      <td>982</td>\n",
       "      <td>441</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>10754</td>\n",
       "      <td>98</td>\n",
       "      <td>[12.83923376553413, 10.173023882320116, 7.9754...</td>\n",
       "      <td>[0.1109979632490764, 0.2464358461243072, 0.368...</td>\n",
       "      <td>[9.291494821247301, 7.439686325681468, 5.87546...</td>\n",
       "      <td>[0.2445820411292392, 0.35913311383303476, 0.46...</td>\n",
       "      <td>1.596405</td>\n",
       "      <td>0.829932</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>['beagle', 'bernese_mountain_dog', 'dhole', 'e...</td>\n",
       "      <td>982</td>\n",
       "      <td>441</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>31265</td>\n",
       "      <td>97</td>\n",
       "      <td>[12.956492519184431, 12.666583076756744, 12.19...</td>\n",
       "      <td>[0.09674134299674976, 0.09979633445227462, 0.1...</td>\n",
       "      <td>[11.453247186938306, 10.903718258943352, 10.12...</td>\n",
       "      <td>[0.10835913690989231, 0.12074303516293458, 0.1...</td>\n",
       "      <td>1.002360</td>\n",
       "      <td>0.866213</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>['beagle', 'bernese_mountain_dog', 'dhole', 'e...</td>\n",
       "      <td>982</td>\n",
       "      <td>441</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>5905</td>\n",
       "      <td>98</td>\n",
       "      <td>[11.05484362483753, 4.596699682126949, 1.94658...</td>\n",
       "      <td>[0.21792260443605863, 0.6181262844448905, 0.82...</td>\n",
       "      <td>[5.4228526977562685, 2.6057197951679996, 1.821...</td>\n",
       "      <td>[0.5325077588528672, 0.7368421216867288, 0.817...</td>\n",
       "      <td>1.100073</td>\n",
       "      <td>0.900227</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>['beagle', 'bernese_mountain_dog', 'dhole', 'e...</td>\n",
       "      <td>982</td>\n",
       "      <td>441</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>21204</td>\n",
       "      <td>98</td>\n",
       "      <td>[12.751901368259656, 11.585275949140188, 9.835...</td>\n",
       "      <td>[0.10285132322194862, 0.15274949047084738, 0.2...</td>\n",
       "      <td>[11.126427582542963, 8.781500400035373, 7.3063...</td>\n",
       "      <td>[0.13622290855590774, 0.2260061960563571, 0.39...</td>\n",
       "      <td>0.838413</td>\n",
       "      <td>0.900227</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>['beagle', 'bernese_mountain_dog', 'dhole', 'e...</td>\n",
       "      <td>982</td>\n",
       "      <td>441</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>10832</td>\n",
       "      <td>98</td>\n",
       "      <td>[11.826030935143745, 7.1247867061747066, 5.819...</td>\n",
       "      <td>[0.1945010152040334, 0.5132382906624353, 0.607...</td>\n",
       "      <td>[7.573710592169511, 6.633380925323203, 6.06647...</td>\n",
       "      <td>[0.4705882293890135, 0.5417956471812245, 0.569...</td>\n",
       "      <td>1.561892</td>\n",
       "      <td>0.882086</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>['beagle', 'bernese_mountain_dog', 'dhole', 'e...</td>\n",
       "      <td>982</td>\n",
       "      <td>441</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>6412</td>\n",
       "      <td>98</td>\n",
       "      <td>[12.641976358448657, 11.121710703474927, 8.528...</td>\n",
       "      <td>[0.09266802237621392, 0.17617107906555207, 0.3...</td>\n",
       "      <td>[10.134136474538513, 7.928750395405772, 5.1026...</td>\n",
       "      <td>[0.18575851162520723, 0.29411763321873574, 0.4...</td>\n",
       "      <td>0.986681</td>\n",
       "      <td>0.882086</td>\n",
       "      <td>sgd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>['beagle', 'bernese_mountain_dog', 'dhole', 'e...</td>\n",
       "      <td>982</td>\n",
       "      <td>441</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>11184</td>\n",
       "      <td>97</td>\n",
       "      <td>[12.45427427078216, 10.495390136470133, 9.0997...</td>\n",
       "      <td>[0.12016293368550765, 0.2433808551847085, 0.32...</td>\n",
       "      <td>[10.441062538985497, 8.977009621197963, 7.5670...</td>\n",
       "      <td>[0.22910216293836894, 0.32817337664288265, 0.3...</td>\n",
       "      <td>1.390529</td>\n",
       "      <td>0.850340</td>\n",
       "      <td>adam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                races  training_len  \\\n",
       "0   ['beagle', 'bernese_mountain_dog', 'dhole', 'e...           982   \n",
       "1   ['beagle', 'bernese_mountain_dog', 'dhole', 'e...           982   \n",
       "2   ['beagle', 'bernese_mountain_dog', 'dhole', 'e...           982   \n",
       "3   ['beagle', 'bernese_mountain_dog', 'dhole', 'e...           982   \n",
       "4   ['beagle', 'bernese_mountain_dog', 'dhole', 'e...           982   \n",
       "5   ['beagle', 'bernese_mountain_dog', 'dhole', 'e...           982   \n",
       "6   ['beagle', 'bernese_mountain_dog', 'dhole', 'e...           982   \n",
       "7   ['beagle', 'bernese_mountain_dog', 'dhole', 'e...           982   \n",
       "8   ['beagle', 'bernese_mountain_dog', 'dhole', 'e...           982   \n",
       "9   ['beagle', 'bernese_mountain_dog', 'dhole', 'e...           982   \n",
       "10  ['beagle', 'bernese_mountain_dog', 'dhole', 'e...           982   \n",
       "11  ['beagle', 'bernese_mountain_dog', 'dhole', 'e...           982   \n",
       "12  ['beagle', 'bernese_mountain_dog', 'dhole', 'e...           982   \n",
       "\n",
       "    testing_len  n_races  batch_size  learning_rate  fitting_time  \\\n",
       "0           441       10         200       0.000008          7584   \n",
       "1           441       10         200       0.000008         21151   \n",
       "2           441       10         200       0.000019          5452   \n",
       "3           441       10         200       0.000019         11787   \n",
       "4           441       10         200       0.000076          3344   \n",
       "5           441       10         200       0.000076          7370   \n",
       "6           441       10         300       0.000008         10754   \n",
       "7           441       10         300       0.000008         31265   \n",
       "8           441       10         300       0.000050          5905   \n",
       "9           441       10         300       0.000050         21204   \n",
       "10          441       10         300       0.000059         10832   \n",
       "11          441       10         300       0.000059          6412   \n",
       "12          441       10         200       0.000005         11184   \n",
       "\n",
       "    prediction_time                                      epochs_losses  \\\n",
       "0               109  [11.640229279543377, 8.675667757900571, 6.2707...   \n",
       "1                97  [13.164204929608191, 12.914754133360448, 12.32...   \n",
       "2                97  [11.432109793917467, 6.4637340460192645, 3.881...   \n",
       "3                98  [12.859470243123786, 11.982571741714011, 10.75...   \n",
       "4                97  [10.06785662256773, 4.840170306732116, 3.07574...   \n",
       "5               102  [11.965150679687376, 9.44600970196384, 6.06742...   \n",
       "6                98  [12.83923376553413, 10.173023882320116, 7.9754...   \n",
       "7                97  [12.956492519184431, 12.666583076756744, 12.19...   \n",
       "8                98  [11.05484362483753, 4.596699682126949, 1.94658...   \n",
       "9                98  [12.751901368259656, 11.585275949140188, 9.835...   \n",
       "10               98  [11.826030935143745, 7.1247867061747066, 5.819...   \n",
       "11               98  [12.641976358448657, 11.121710703474927, 8.528...   \n",
       "12               97  [12.45427427078216, 10.495390136470133, 9.0997...   \n",
       "\n",
       "                                    epochs_accuracies  \\\n",
       "0   [0.13645621251064502, 0.320773934152607, 0.486...   \n",
       "1   [0.10081466296479076, 0.11099796265727876, 0.1...   \n",
       "2   [0.16598777837156037, 0.4755600845012548, 0.67...   \n",
       "3   [0.11608961356572367, 0.13849287499842478, 0.1...   \n",
       "4   [0.2983706677275617, 0.6598778002859376, 0.790...   \n",
       "5   [0.1395112039661699, 0.29633401464784703, 0.52...   \n",
       "6   [0.1109979632490764, 0.2464358461243072, 0.368...   \n",
       "7   [0.09674134299674976, 0.09979633445227462, 0.1...   \n",
       "8   [0.21792260443605863, 0.6181262844448905, 0.82...   \n",
       "9   [0.10285132322194862, 0.15274949047084738, 0.2...   \n",
       "10  [0.1945010152040334, 0.5132382906624353, 0.607...   \n",
       "11  [0.09266802237621392, 0.17617107906555207, 0.3...   \n",
       "12  [0.12016293368550765, 0.2433808551847085, 0.32...   \n",
       "\n",
       "                                    epochs_val_losses  \\\n",
       "0   [8.413873997266078, 6.248528911602387, 4.20287...   \n",
       "1   [12.512846996909694, 11.754830443084055, 10.95...   \n",
       "2   [8.568536076383324, 4.294536177218883, 3.03362...   \n",
       "3   [11.430217060880395, 9.780132278938412, 7.9990...   \n",
       "4   [5.666034890402212, 3.9021638406688584, 2.7525...   \n",
       "5   [9.814261461559095, 6.352773416153049, 4.72292...   \n",
       "6   [9.291494821247301, 7.439686325681468, 5.87546...   \n",
       "7   [11.453247186938306, 10.903718258943352, 10.12...   \n",
       "8   [5.4228526977562685, 2.6057197951679996, 1.821...   \n",
       "9   [11.126427582542963, 8.781500400035373, 7.3063...   \n",
       "10  [7.573710592169511, 6.633380925323203, 6.06647...   \n",
       "11  [10.134136474538513, 7.928750395405772, 5.1026...   \n",
       "12  [10.441062538985497, 8.977009621197963, 7.5670...   \n",
       "\n",
       "                                epochs_val_accuracies  test_loss  \\\n",
       "0   [0.29411764899643583, 0.43343653213867095, 0.5...   1.335279   \n",
       "1   [0.10216718466935143, 0.12074303737734862, 0.1...   1.216085   \n",
       "2   [0.3188854513614908, 0.5975232375295538, 0.684...   1.159407   \n",
       "3   [0.12074303419412843, 0.18885448999449195, 0.2...   1.033548   \n",
       "4   [0.5789473896425206, 0.7151702664584937, 0.798...   2.807766   \n",
       "5   [0.24767801368568704, 0.49535603161566766, 0.6...   1.040372   \n",
       "6   [0.2445820411292392, 0.35913311383303476, 0.46...   1.596405   \n",
       "7   [0.10835913690989231, 0.12074303516293458, 0.1...   1.002360   \n",
       "8   [0.5325077588528672, 0.7368421216867288, 0.817...   1.100073   \n",
       "9   [0.13622290855590774, 0.2260061960563571, 0.39...   0.838413   \n",
       "10  [0.4705882293890135, 0.5417956471812245, 0.569...   1.561892   \n",
       "11  [0.18575851162520723, 0.29411763321873574, 0.4...   0.986681   \n",
       "12  [0.22910216293836894, 0.32817337664288265, 0.3...   1.390529   \n",
       "\n",
       "    test_accuracy optimizer  \n",
       "0        0.868481      adam  \n",
       "1        0.854875       sgd  \n",
       "2        0.884354      adam  \n",
       "3        0.877551       sgd  \n",
       "4        0.807256      adam  \n",
       "5        0.897959       sgd  \n",
       "6        0.829932      adam  \n",
       "7        0.866213       sgd  \n",
       "8        0.900227      adam  \n",
       "9        0.900227       sgd  \n",
       "10       0.882086      adam  \n",
       "11       0.882086       sgd  \n",
       "12       0.850340      adam  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluation = pd.read_csv('df_evaluation_final.csv')\n",
    "df_evaluation.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "df_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_acc_index = df_evaluation[df_evaluation['test_accuracy']==np.max(df_evaluation['test_accuracy'])].index[0]\n",
    "best_acc_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "races                    ['beagle', 'bernese_mountain_dog', 'dhole', 'e...\n",
       "training_len                                                           982\n",
       "testing_len                                                            441\n",
       "n_races                                                                 10\n",
       "batch_size                                                             300\n",
       "learning_rate                                                  4.96803e-05\n",
       "fitting_time                                                          5905\n",
       "prediction_time                                                         98\n",
       "epochs_losses            [11.05484362483753, 4.596699682126949, 1.94658...\n",
       "epochs_accuracies        [0.21792260443605863, 0.6181262844448905, 0.82...\n",
       "epochs_val_losses        [5.4228526977562685, 2.6057197951679996, 1.821...\n",
       "epochs_val_accuracies    [0.5325077588528672, 0.7368421216867288, 0.817...\n",
       "test_loss                                                          1.10007\n",
       "test_accuracy                                                     0.900227\n",
       "optimizer                                                             adam\n",
       "Name: 8, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_evaluation.loc[best_acc_index,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beagle',\n",
       " 'bernese_mountain_dog',\n",
       " 'dhole',\n",
       " 'english_setter',\n",
       " 'japanese_spaniel',\n",
       " 'kelpie',\n",
       " 'labrador_retriever',\n",
       " 'rottweiler',\n",
       " 'siberian_husky',\n",
       " 'west_highland_white_terrier']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OPTIMIZER = df_evaluation.loc[best_acc_index,'optimizer']\n",
    "BATCH_SIZE = df_evaluation.loc[best_acc_index,'batch_size']\n",
    "LEARNING_RATE = df_evaluation.loc[best_acc_index,'learning_rate']\n",
    "EPOCHS = 100 \n",
    "NN_CALLBACKS = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "\n",
    "L_filtered_races = pickle.load(open(pickles_path+\"L_10_filtered_races.p\", \"rb\" ))\n",
    "RACE_NUMBER = len(L_filtered_races)\n",
    "L_filtered_races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'L_batch_sizes = [200]\\ndict_lr_ranges = {\\n    0:[0.000076,0.000076]\\n}\\nEPOCHS = 100 \\nNN_CALLBACKS = EarlyStopping(monitor=\\'val_loss\\', min_delta=0, patience=3, verbose=0, mode=\\'auto\\')\\nL_filtered_races = pickle.load(open(pickles_path+\"L_10_filtered_races.p\", \"rb\" ))\\nRACE_NUMBER = len(L_filtered_races)\\nL_filtered_races'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"L_batch_sizes = [200]\n",
    "dict_lr_ranges = {\n",
    "    0:[0.000076,0.000076]\n",
    "}\n",
    "EPOCHS = 100 \n",
    "NN_CALLBACKS = EarlyStopping(monitor='val_loss', min_delta=0, patience=3, verbose=0, mode='auto')\n",
    "L_filtered_races = pickle.load(open(pickles_path+\"L_10_filtered_races.p\", \"rb\" ))\n",
    "RACE_NUMBER = len(L_filtered_races)\n",
    "L_filtered_races\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "        **<font color='#D2691E'size=\"4\">II) Model training</font>**\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered_races : ['beagle', 'bernese_mountain_dog', 'dhole', 'english_setter', 'japanese_spaniel', 'kelpie', 'labrador_retriever', 'rottweiler', 'siberian_husky', 'west_highland_white_terrier']\n",
      "\n",
      "building the train and test datasets ...\n",
      "\n",
      "training the model with params :\n",
      "Batch size = 300 | Learning rate = 4.968027319721656e-05\n",
      "fitting the model ...\n",
      "\n",
      "Train on 982 samples, validate on 323 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-eee0651f67c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     76\u001b[0m                         \u001b[0mcallbacks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mNN_CALLBACKS\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m                         verbose=1)\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[0mfitting_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0minit_fitting_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "iter_start_time = time.time()\n",
    "\n",
    "print('filtered_races : %s'%L_filtered_races)\n",
    "print()\n",
    "print('building the train and test datasets ...')\n",
    "print()\n",
    "dict_data = build_train_validation_and_test_datasets(L_filtered_races,'label_encoder_final_model','vectorizer_final_model')\n",
    "\n",
    "X_train = dict_data['X_train']\n",
    "X_val = dict_data['X_val']\n",
    "X_test = dict_data['X_test']\n",
    "    \n",
    "y_train = dict_data['y_train']\n",
    "y_val = dict_data['y_val']\n",
    "y_test = dict_data['y_test']\n",
    "            \n",
    "training_len = X_train.shape[0]\n",
    "testing_len = X_test.shape[0]\n",
    "\n",
    "print(\"training the model with params :\")\n",
    "print(\"Batch size = %s | Learning rate = %s\"%(BATCH_SIZE,LEARNING_RATE))\n",
    "\n",
    "# Charger VGG-16 pré-entraîné sur ImageNet et sans les couches fully-connected\n",
    "model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# choose the layers which are updated by training\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Récupérer la sortie de ce réseau\n",
    "x = model.output\n",
    "# Ajouter la fonction Flatten à la nouvelle couche fully-connected pour la classification à 2 classes\n",
    "predictions = Flatten()(x)\n",
    "\n",
    "# Définir le nouveau modèle\n",
    "new_model = Model(inputs=model.input, outputs=predictions)\n",
    "\n",
    "# Ajout d'une couche Fully connected à 4096 neurones ayant une fonction d'activation \"relu\"\n",
    "x = new_model.output\n",
    "predictions = Dense(4096, activation='relu')(x)\n",
    "new_model = Model(inputs=new_model.input, outputs=predictions)\n",
    "\n",
    "\"\"\"Ajout d'une couche Dropout\"\"\"\n",
    "x = new_model.output\n",
    "dropout = Dropout(0.2)(x)\n",
    "new_model = Model(inputs=new_model.input, outputs=dropout)\n",
    "\n",
    "\n",
    "# Ajout d'une couche supplémentaire Fully connected à 4096 neurones ayant une fonction d'activation \"relu\"\n",
    "x = new_model.output\n",
    "predictions = Dense(4096, activation='relu')(x)\n",
    "new_model = Model(inputs=new_model.input, outputs=predictions)\n",
    "\n",
    "\"\"\"Ajout d'une couche Dropout\"\"\"\n",
    "x = new_model.output\n",
    "dropout = Dropout(0.2)(x)\n",
    "new_model = Model(inputs=new_model.input, outputs=dropout)\n",
    "\n",
    "# Ajout d'une couche Fully connected à 2 neurones ayant une fonction d'activation \"softmax\"\n",
    "x = new_model.output\n",
    "predictions = Dense(RACE_NUMBER, activation='softmax')(x)\n",
    "new_model = Model(inputs=new_model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "# Compiler le modèle\n",
    "new_model.compile(loss=\"categorical_crossentropy\", optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "init_fitting_time = time.time()\n",
    "print('fitting the model ...')\n",
    "print()\n",
    "# Entraîner sur les données d'entraînement (X_train, y_train)\n",
    "history = new_model.fit(X_train,\n",
    "                        y_train,\n",
    "                        validation_data=(X_val,y_val),\n",
    "                        epochs=EPOCHS,\n",
    "                        callbacks = [NN_CALLBACKS],\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        verbose=1)\n",
    "\n",
    "fitting_time = int(time.time() - init_fitting_time)\n",
    "print('fitting_time : %s seconds'%fitting_time)\n",
    "print()\n",
    "\n",
    "init_prediction_time = time.time()\n",
    "print('computing the accuracy on the test data ...')\n",
    "print()\n",
    "performances = new_model.evaluate(X_test, y_test, verbose=0)\n",
    "test_loss = performances[0]\n",
    "test_accuracy = performances[1]\n",
    "print(\"test_loss : %s | test_accuracy : %s\"%(test_loss,test_accuracy))\n",
    "prediction_time = int(time.time() - init_prediction_time)\n",
    "print('prediction_time : %s seconds'%prediction_time)\n",
    "print()\n",
    "\n",
    "print('training_time : %s seconds'% (time.time() - init_training_time))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = new_model.to_json()\n",
    "with open(\"CNN_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "new_model.save_weights(\"CNN_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered_races : ['beagle', 'bernese_mountain_dog', 'dhole', 'english_setter', 'japanese_spaniel', 'kelpie', 'labrador_retriever', 'rottweiler', 'siberian_husky', 'west_highland_white_terrier']\n",
      "\n",
      "building the train and test datasets ...\n",
      "\n",
      "looping over the vgg16 parameters ...\n",
      "\n",
      "\n",
      "\n",
      "#############################################################################################\n",
      "training the model with params :\n",
      "Batch size = 200 | Learning rate = 7.6e-05\n",
      "fitting the model ...\n",
      "optimizer : sgd\n",
      "\n",
      "Train on 982 samples, validate on 323 samples\n",
      "Epoch 1/100\n",
      "982/982 [==============================] - 336s 342ms/step - loss: 11.4004 - acc: 0.1568 - val_loss: 8.3971 - val_acc: 0.3220\n",
      "Epoch 2/100\n",
      "982/982 [==============================] - 321s 327ms/step - loss: 8.8687 - acc: 0.3289 - val_loss: 5.1367 - val_acc: 0.5697\n",
      "Epoch 3/100\n",
      "982/982 [==============================] - 303s 309ms/step - loss: 6.0790 - acc: 0.5092 - val_loss: 3.3018 - val_acc: 0.6935\n",
      "Epoch 4/100\n",
      "982/982 [==============================] - 307s 313ms/step - loss: 3.5385 - acc: 0.6996 - val_loss: 2.5580 - val_acc: 0.7585\n",
      "Epoch 5/100\n",
      "982/982 [==============================] - 307s 313ms/step - loss: 2.7219 - acc: 0.7790 - val_loss: 2.6166 - val_acc: 0.7678\n",
      "Epoch 6/100\n",
      "982/982 [==============================] - 314s 320ms/step - loss: 2.0971 - acc: 0.8259 - val_loss: 2.0848 - val_acc: 0.8266\n",
      "Epoch 7/100\n",
      "982/982 [==============================] - 316s 322ms/step - loss: 1.5445 - acc: 0.8676 - val_loss: 1.3439 - val_acc: 0.8421\n",
      "Epoch 8/100\n",
      "982/982 [==============================] - 327s 333ms/step - loss: 1.0935 - acc: 0.8971 - val_loss: 1.1727 - val_acc: 0.8576\n",
      "Epoch 9/100\n",
      "982/982 [==============================] - 326s 332ms/step - loss: 0.8274 - acc: 0.9053 - val_loss: 0.9148 - val_acc: 0.9009\n",
      "Epoch 10/100\n",
      "982/982 [==============================] - 329s 335ms/step - loss: 0.7776 - acc: 0.9297 - val_loss: 0.9624 - val_acc: 0.9009\n",
      "Epoch 11/100\n",
      "982/982 [==============================] - 319s 325ms/step - loss: 0.4360 - acc: 0.9542 - val_loss: 0.8347 - val_acc: 0.9226\n",
      "Epoch 12/100\n",
      "982/982 [==============================] - 313s 319ms/step - loss: 0.2398 - acc: 0.9674 - val_loss: 0.8340 - val_acc: 0.9133\n",
      "Epoch 13/100\n",
      "982/982 [==============================] - 314s 320ms/step - loss: 0.2658 - acc: 0.9654 - val_loss: 0.8043 - val_acc: 0.9071\n",
      "Epoch 14/100\n",
      "982/982 [==============================] - 315s 321ms/step - loss: 0.2590 - acc: 0.9664 - val_loss: 0.7512 - val_acc: 0.9195\n",
      "Epoch 15/100\n",
      "982/982 [==============================] - 329s 335ms/step - loss: 0.1793 - acc: 0.9807 - val_loss: 0.7278 - val_acc: 0.9226\n",
      "Epoch 16/100\n",
      "982/982 [==============================] - 327s 333ms/step - loss: 0.1661 - acc: 0.9796 - val_loss: 0.6683 - val_acc: 0.9226\n",
      "Epoch 17/100\n",
      "982/982 [==============================] - 323s 329ms/step - loss: 0.1345 - acc: 0.9827 - val_loss: 0.6428 - val_acc: 0.9226\n",
      "Epoch 18/100\n",
      "982/982 [==============================] - 336s 342ms/step - loss: 0.1231 - acc: 0.9827 - val_loss: 0.6760 - val_acc: 0.9226\n",
      "Epoch 19/100\n",
      "982/982 [==============================] - 332s 338ms/step - loss: 0.1262 - acc: 0.9857 - val_loss: 0.7118 - val_acc: 0.9226\n",
      "Epoch 20/100\n",
      "982/982 [==============================] - 323s 329ms/step - loss: 0.1028 - acc: 0.9868 - val_loss: 0.6752 - val_acc: 0.9288\n",
      "fitting_time : 6417 seconds\n",
      "\n",
      "computing the accuracy on the test data ...\n",
      "\n",
      "test_loss : 0.8037770791260735 | test_accuracy : 0.9070294784580499\n",
      "prediction_time : 101 seconds\n",
      "\n",
      "training_time : 6520.274518728256 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iter_start_time = time.time()\n",
    "\n",
    "print('filtered_races : %s'%L_filtered_races)\n",
    "print()\n",
    "print('building the train and test datasets ...')\n",
    "print()\n",
    "dict_data = build_train_validation_and_test_datasets(L_filtered_races,'label_encoder_final_model','vectorizer_final_model')\n",
    "\n",
    "X_train = dict_data['X_train']\n",
    "X_val = dict_data['X_val']\n",
    "X_test = dict_data['X_test']\n",
    "    \n",
    "y_train = dict_data['y_train']\n",
    "y_val = dict_data['y_val']\n",
    "y_test = dict_data['y_test']\n",
    "            \n",
    "training_len = X_train.shape[0]\n",
    "testing_len = X_test.shape[0]\n",
    "            \n",
    "print('looping over the vgg16 parameters ...')\n",
    "print()\n",
    "for lr_iteration in range(0,1):            \n",
    "    for BATCH_SIZE in L_batch_sizes:\n",
    "        for key in dict_lr_ranges.keys():\n",
    "            lr_interval = dict_lr_ranges[key]\n",
    "            LEARNING_RATE = random.uniform(lr_interval[0], lr_interval[1])\n",
    "            init_training_time = time.time()\n",
    "            print()\n",
    "            print()\n",
    "            print(\"#############################################################################################\")\n",
    "            print(\"training the model with params :\")\n",
    "            print(\"Batch size = %s | Learning rate = %s\"%(BATCH_SIZE,LEARNING_RATE))\n",
    "\n",
    "            for optimizer in ['sgd']:\n",
    "                # Charger VGG-16 pré-entraîné sur ImageNet et sans les couches fully-connected\n",
    "                model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "                # choose the layers which are updated by training\n",
    "                for layer in model.layers:\n",
    "                    layer.trainable = False\n",
    "\n",
    "                # Récupérer la sortie de ce réseau\n",
    "                x = model.output\n",
    "                # Ajouter la fonction Flatten à la nouvelle couche fully-connected pour la classification à 2 classes\n",
    "                predictions = Flatten()(x)\n",
    "\n",
    "                # Définir le nouveau modèle\n",
    "                new_model = Model(inputs=model.input, outputs=predictions)\n",
    "\n",
    "                # Ajout d'une couche Fully connected à 4096 neurones ayant une fonction d'activation \"relu\"\n",
    "                x = new_model.output\n",
    "                predictions = Dense(4096, activation='relu')(x)\n",
    "                new_model = Model(inputs=new_model.input, outputs=predictions)\n",
    "\n",
    "                \"\"\"Ajout d'une couche Dropout\"\"\"\n",
    "                x = new_model.output\n",
    "                dropout = Dropout(0.2)(x)\n",
    "                new_model = Model(inputs=new_model.input, outputs=dropout)\n",
    "\n",
    "\n",
    "                # Ajout d'une couche supplémentaire Fully connected à 4096 neurones ayant une fonction d'activation \"relu\"\n",
    "                x = new_model.output\n",
    "                predictions = Dense(4096, activation='relu')(x)\n",
    "                new_model = Model(inputs=new_model.input, outputs=predictions)\n",
    "\n",
    "                \"\"\"Ajout d'une couche Dropout\"\"\"\n",
    "                x = new_model.output\n",
    "                dropout = Dropout(0.2)(x)\n",
    "                new_model = Model(inputs=new_model.input, outputs=dropout)\n",
    "\n",
    "                # Ajout d'une couche Fully connected à 2 neurones ayant une fonction d'activation \"softmax\"\n",
    "                x = new_model.output\n",
    "                predictions = Dense(RACE_NUMBER, activation='softmax')(x)\n",
    "                new_model = Model(inputs=new_model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "                # Compiler le modèle\n",
    "                if optimizer == 'adam':\n",
    "                    nn_optimizer = Adam(lr=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "                if optimizer == 'sgd':\n",
    "                    nn_optimizer = SGD(lr=LEARNING_RATE, momentum=0.9)\n",
    "                new_model.compile(loss=\"categorical_crossentropy\", optimizer=nn_optimizer, metrics=[\"accuracy\"])\n",
    "\n",
    "                init_fitting_time = time.time()\n",
    "                print('fitting the model ...')\n",
    "                print('optimizer : %s'%optimizer)\n",
    "                print()\n",
    "                # Entraîner sur les données d'entraînement (X_train, y_train)\n",
    "                history = new_model.fit(X_train,\n",
    "                                        y_train,\n",
    "                                        validation_data=(X_val,y_val),\n",
    "                                        epochs=EPOCHS,\n",
    "                                        callbacks = [NN_CALLBACKS],\n",
    "                                        batch_size=BATCH_SIZE,\n",
    "                                        verbose=1)\n",
    "\n",
    "                fitting_time = int(time.time() - init_fitting_time)\n",
    "                print('fitting_time : %s seconds'%fitting_time)\n",
    "                print()\n",
    "\n",
    "                init_prediction_time = time.time()\n",
    "                print('computing the accuracy on the test data ...')\n",
    "                print()\n",
    "                performances = new_model.evaluate(X_test, y_test, verbose=0)\n",
    "                test_loss = performances[0]\n",
    "                test_accuracy = performances[1]\n",
    "                print(\"test_loss : %s | test_accuracy : %s\"%(test_loss,test_accuracy))\n",
    "                prediction_time = int(time.time() - init_prediction_time)\n",
    "                print('prediction_time : %s seconds'%prediction_time)\n",
    "                print()\n",
    "\n",
    "                print('training_time : %s seconds'% (time.time() - init_training_time))\n",
    "                print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
