{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img id=\"r-1060983\" data-claire-element-id=\"1061343\" src=\"http://www.siteduzero.com/favicon.ico\" alt=\"Image utilisateur\">\n",
    "<p>\n",
    "    The aim of this project is to put in place methods that make it possible to identify the race from an incoming dog image.\n",
    "    This project is broken down into several stages whose sequencing is illustrated on the \"ROADMAP\" below:\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <center>\n",
    "        **<font color='\t#D2691E'size=\"6\">ROADMAP</font>**\n",
    "    </center>\n",
    "</p>\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"./images/part_0.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "     The \"ROADMAP\" breaks down into three main stages: Preprocessing, Learning and Evaluation\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <b> Preprocessing </b>:\n",
    "</p>\n",
    "<p>\n",
    "    - <b> part_1_renaming_folders_and_files </b>: In this program, we restructure the folder names associated with dog races as well as the names of dog pictures. The goal is to have a more appropriate and understandable data structure.\n",
    "</p>\n",
    "<p>\n",
    "    - <b> part_2_datasets_building </b>: This program builds the train, validation and test perimeters that will be used to build the learning models.\n",
    "</p>\n",
    "<p>\n",
    "    ---> Classical approach: A dictionary containing the train and test perimeters is built. The SIFT features associated with each image of the train and test perimeters are also constructed. Two dataframes (one for the train data, another for the test data) are then saved for the next step. The granularity of the data is at the level of the SIFT features (a row of datasets corresponds to a feature detected on an image, a given image having N features SIFT)\n",
    "</p>\n",
    "<p>\n",
    "    ---> CNN approach: Another dictionary, containing the train perimeters, validation and test, is built for the CNN approach.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <b> Learning (classical approach) </b>:\n",
    "</p>\n",
    "<p>\n",
    "    - <b> part_3_classical_approach_SIFT_features_analysis </b>: In this program, we perform analyzes on SIFT features generated for images and dogs races\n",
    "</p>\n",
    "<p>\n",
    "    - <b> part_4_classical_approach_clustering_KM </b>: In this program, we build different datasets of bag of visual words. To do this, we implement different KMeans clustering: 50, 100, 200,300 and 500 clusters. The bag of visual words datasets are then obtained in two steps:\n",
    "</p>\n",
    "<p>\n",
    "    ---> Aggregation of the SIFT descriptor columns of each image-level feature: For each descriptor (descriptor) on all feature lines attached to the image. The granularity of the data becomes that of the images.\n",
    "</p>\n",
    "<p>\n",
    "    ---> Standardization, for each image, of the sums of each descriptor relative to the sum of all the descriptors\n",
    "</p>\n",
    "<p>\n",
    "A bag of visual words dataset is built for each previously calculated type of clustering: each bag of visual words dataset is saved for the next step.\n",
    "</p>\n",
    "<p>\n",
    "    - <b> part_5_classical_approach_bag_of_visual_words_classification </b>: This program implements three classification algorithms: Logistic Regression, Support Vector Classifier, and Random Forest. The goal is to predict the dogs races through the datasets of bag of visual words.\n",
    "</p>\n",
    "<p>\n",
    "    ---> A first part uses, for a given algorithm, cross validation.\n",
    "</p>\n",
    "<p>\n",
    "    ---> A second part uses the best parameters of the cross validation performed on the algorithm in order to build a final learning model.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "     <b> Evaluation (classical approach) </b>:\n",
    "</p>\n",
    "<p>\n",
    "     - <b> part_6_classical_approach_classification_iterations </b>: In this program, we loop over the previous script, <b> part_5_classical_approach_bag_of_visual_words_classification </b>, in order to implement its classification algorithms with all bag of visual words datasets.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <b> Learning (CNN approach) </b>:\n",
    "</p>\n",
    "<p>\n",
    "N.B: These notebooks have been set up thanks to the work done on the notebooks provided in the appendix: <b> Annex_1_CNN_approach_transfer_learning_over_parameters </b> and <b> Annex_2_CNN_approach_results_analyzis </b>\n",
    "</p>\n",
    "<p>\n",
    "</p>\n",
    "<p>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    - <b> part_7_CNN_approach_transfer_learning </b>: This program implements the transfer learning of the VGG16 model driven on IMAGENET.\n",
    "</p>\n",
    "We freeze the learned weights on the first 13 layers of convolution and we train only the last 3 layers fully connected.\n",
    "<p>\n",
    "</p>\n",
    "Various network parameters (Batch size, learning rate, and optimizer) are varied.\n",
    "<p>\n",
    "    The training is carried out over 100 eras. It is performed by cross-validation on the validation perimeter defined in <b> part_2_datasets_building </b>. An \"Early Stopping\" is set so that the training ends when the validation loss does not change after 3 epochs.\n",
    "</p>\n",
    "<p>\n",
    "    As a regularization, a Dropout layer is added after the first two layers fully connected. Each dropout layer obscures 20% of the neural signals it receives.\n",
    "\n",
    "</p>\n",
    "\n",
    "\n",
    "<p>\n",
    "    - <b> part_8_CNN_approach_results_analyzis_transfer_learning </b>: This program analyzes the results of the <b> part_7_CNN_approach_transfer_learning </b> notebook processes.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "     <b> Evaluation (CNN approach) </b>:\n",
    "</p>\n",
    "<p>\n",
    "     - <b> part_9_CNN_approach_final_model </b>: In this program, we drive a final neural network based on the best results obtained in <b> part_8_CNN_approach_results_analyzis_transfer_learning </b>.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <center>\n",
    "        **<font color='\t#D2691E'size=\"6\">HOW TO USE THE FINAL APPLICATION</font>**\n",
    "    </center>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    The CNN approach allowed me to build a flask application which is in <a href=\"http://bit.ly/mk_cv_dogs\">another github project</a> :  \n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"./images/instructions_application.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
