{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NOTEBOOK_INFORMATION-->\n",
    "<img id=\"r-1060983\" data-claire-element-id=\"1061343\" src=\"http://www.siteduzero.com/favicon.ico\" alt=\"Image utilisateur\">\n",
    "    <p>\n",
    "        **<font color='#D2691E'size=\"6\">Projet n°7 : Indexations automatiques d'images : README</font>**.\n",
    "    </p>\n",
    "    <p>\n",
    "        Ce notebook décrit la démarche et les différents traitements du projet n°7.\n",
    "    </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "Le projet 7 a pour but de mettre en place des procédés permettant, à partir d'une image de chien en entrée, d'identifier sa race. Ce projet se décompose en plusieurs étapes dont le séquencement est illustré sur la \"ROADMAP\" ci-dessous :\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <center>\n",
    "        **<font color='\t#D2691E'size=\"6\">ROADMAP</font>**\n",
    "    </center>\n",
    "</p>\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"./images/part_0.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    La \"ROADMAP\" se décompose en trois grandes étapes : Preprocessing, Learning et Evaluation \n",
    "</p>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <b>Preprocessing</b> :\n",
    "</p>\n",
    "<p>\n",
    "    - <b>part_1_renaming_folders_and_files</b> : Dans ce programme, on restructure les noms de dossiers associés aux races de chiens ainsi que les noms des photos de chiens. Le but est d'avoir une structuration des données plus adaptée et compréhensible.\n",
    "</p>\n",
    "<p>\n",
    "    - <b>part_2_datasets_building</b> : Dans ce programme, on construit les périmètres de train, validation et test qui serviront à bâtir les modèles d'apprentissage.\n",
    "</p>\n",
    "<p>\n",
    "    ---> Approche classique : Un dictionnaire contenant les périmètres de train et de test est construit. On construit également les features SIFT associées à chaque image des périmètres de train et de test. Deux dataframes (un pour les données de train, un autre pour les données de test) sont alors sauvegardés pour l'étape suivante. La granularité des données est au niveau des features SIFT (une ligne des datasets correspond à une feature détectée sur une image, une image donnée ayant N features SIFT)\n",
    "</p>\n",
    "<p>\n",
    "    ---> Approche CNN : Un autre dictionnaire, contenant les périmètres de train, validation et test, est construit pour l'approche CNN.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <b>Learning (approche classique)</b>:\n",
    "</p>\n",
    "<p>\n",
    "    - <b>part_3_classical_approach_SIFT_features_analysis</b> : Dans ce programme, on effectue des analyses sur les features SIFT générées pour les images et les races de chiens\n",
    "</p>\n",
    "<p>\n",
    "    - <b>part_4_classical_approach_clustering_KM</b> : Dans ce programme, on construit différents datasets de bag of visual words. Pour se faire, on implémente différents clustering KMeans : 50, 100, 200,300 et 500 clusters. Les datasets bag of visual words sont ensuite obtenus en deux étapes :\n",
    "</p>\n",
    "<p>\n",
    "    ---> Agrégation des colonnes des descripteurs SIFT de chaque feature au niveau des images : Pour chaque descripteur SOMME(descripteur) sur toutes les lignes de features rattachées à l'image. La granularité des données devient celle des images.\n",
    "</p>\n",
    "<p>\n",
    "    ---> Normalisation, pour chaque image, des sommes de chaque descripteur relativement à la somme de l'ensemble des descripteurs\n",
    "</p>\n",
    "<p>\n",
    "Un dataset bag of visual words est construit pour chaque type de clustering préalablement calculé : chaque dataset bag of visual words est sauvegardé pour l'étape suivante.\n",
    "</p>\n",
    "<p>\n",
    "    - <b>part_5_classical_approach_bag_of_visual_words_classification</b> : Dans ce programme, on implémente trois algorithmes de classification : Régression logistique, Classifieur à vecteurs de support et Forêts aléatoires. Le but est de prédire la race des chiens grâce aux datasets de bag of visual words.\n",
    "</p>\n",
    "<p>\n",
    "    ---> Une première partie fait appel, pour un algorithme donné, à de la validation croisée.\n",
    "</p>\n",
    "<p>\n",
    "    ---> Une seconde partie fait appel aux meilleurs paramètres de la validation croisée effectuée sur l'algorithme afin de construire un modèle d'apprentissage final.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <b>Evaluation (approche classique)</b>:\n",
    "</p>\n",
    "<p>\n",
    "    - <b>part_6_classical_approach_classification_iterations</b> : Dans ce programme, on boucle sur le script précédent, <b>part_5_classical_approach_bag_of_visual_words_classification</b>, afin d'implémenter ses algorithmes de classification avec l'ensemble des datasets bag of visual words.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <b>Learning (approche CNN)</b>:\n",
    "</p>\n",
    "<p>\n",
    "N.B  : ces notebooks ont été paramétrés grâce au travail effectué  sur les notebooks fournis en annexe : <b>Annex_1_CNN_approach_transfer_learning_over_parameters</b> et <b>Annex_2_CNN_approach_results_analyzis</b> \n",
    "</p>\n",
    "<p>\n",
    "</p>\n",
    "<p>\n",
    "</p>\n",
    "\n",
    "<p>\n",
    "    - <b>part_7_CNN_approach_transfer_learning</b> : Dans ce programme, on implémente le transfer learning du modèle VGG16 entraîné sur IMAGENET.\n",
    "</p>\n",
    "On fige les poids appris sur les 13 premières couches de convolution et on entraîne uniquement les 3 dernières couches fully connected.\n",
    "<p>\n",
    "</p>\n",
    "On fait varier différents paramètres du réseau (Batch size, learning rate, et optimiseur).\n",
    "<p>\n",
    "    L'entraînement s'effectue sur 100 époques. Il est effectué par validation croisée sur le périmètre de validation défini dans <b>part_2_datasets_building</b>. Un \"Early Stopping\" est paramétré de telle sorte que l'entraînement prenne fin lorsque la validation loss n'évolue pas au bout de 3 epoques.\n",
    "</p>\n",
    "<p>\n",
    "    A titre de régularisation, une couche Dropout est ajoutée à la suite des deux premières couches fully connected. Chaque couche dropout occulte 20% des signaux de neurones qu'elle reçoit.\n",
    "\n",
    "</p>\n",
    "\n",
    "\n",
    "<p>\n",
    "    - <b>part_8_CNN_approach_results_analyzis_transfer_learning</b> : Dans ce programme, on analyse les résultats obtenus par les traitements du notebook <b>part_7_CNN_approach_transfer_learning</b>.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <b>Evaluation (approche CNN)</b>:\n",
    "</p>\n",
    "<p>\n",
    "    - <b>part_9_CNN_approach_final_model</b> : Dans ce programme, on entraîne un réseau de neurones final en se basant sur les meilleurs résultats obtenus dans <b>part_8_CNN_approach_results_analyzis_transfer_learning</b>.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    <center>\n",
    "        **<font color='\t#D2691E'size=\"6\">UTILISATION DE L'APPLICATION</font>**\n",
    "    </center>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    L'application est présente dans le fichier <b>dogs_identification.zip</b> : \n",
    "\n",
    "</p>\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"./images/fichier_zip.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"./images/instructions_application.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
